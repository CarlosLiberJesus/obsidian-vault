# Introduction

Did not investigate further, all points to runs you LLM in Amazon GPUs. Or I might be wrong and its their proprietary LLM... not in radar. 

Could become a possibility for deeper training, after much more comprehension, renting our gpus.

- Type: Cloud infrastructure provider.
- Details: AWS Bedrock supports models from Anthropic, Meta, DeepSeek, Mistral, and Amazon. Cline connects to Bedrock’s API.
- Free Option: AWS offers a free tier for Bedrock, but it’s limited (e.g., 1M tokens/month for 2 months). After that, pricing is usage-based (e.g., $0.80/million tokens for Anthropic models). Not a good fit for 3 months of free testing.