# Introduction

While [[Ollama]] is like a backend for LLM that need a frontend (webui or msty), LMStudios is an all-in-one framework. Probably could have both, since one would be active with `ollama run`this looks like a Docker container; so far the only advantage would seem a better picker for models, but probably we will find some .io that will help us filter as well.



